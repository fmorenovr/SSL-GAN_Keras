{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a207473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac806c7a",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c569491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import verifyDir\n",
    "from utils.networks import normalize, unnormalize, plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3c765",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e460c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CIFAR10 import load_real_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc42eb",
   "metadata": {},
   "source": [
    "### Discriminator & Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da029db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CIFAR10 import define_discriminator\n",
    "from utils.CIFAR10 import define_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417a6ca",
   "metadata": {},
   "source": [
    "### Semi-Supervised GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import define_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea76a5",
   "metadata": {},
   "source": [
    "### Selecting sub-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import select_supervised_samples, generate_real_samples\n",
    "from utils.networks import generate_fake_samples, generate_latent_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9408523",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train_gan(generator_model, unsupervised_model, supervised_model, gan_model, \n",
    "              dataset_train, dataset_test, \n",
    "              latent_dim=100, n_epochs=20, n_batch=100, \n",
    "              n_classes=10, label_rate=None, n_samples=None):\n",
    "    \n",
    "    # select supervised dataset_train\n",
    "    X_sup, y_sup = select_supervised_samples(dataset_train, \n",
    "                                             n_classes=n_classes, \n",
    "                                             label_rate=label_rate, \n",
    "                                             n_samples=n_samples)\n",
    "    \n",
    "    print(\"Supervised samples:\", X_sup.shape, y_sup.shape)\n",
    "    \n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset_train[0].shape[0] / n_batch)\n",
    "    \n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    print('n_epochs=%d, n_batch=%d, batch/epoch=%d, steps=%d' % (n_epochs, n_batch, bat_per_epo, n_steps))\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    f_history = open(f\"{LOG_PATH}SSL_GAN.csv\", \"w\")\n",
    "    \n",
    "    f_history.write(\"step;generator_loss;\"\\\n",
    "                    \"unsupervised_real_loss;unsupervised_real_acc;\"\\\n",
    "                    \"unsupervised_fake_loss;unsupervised_fake_acc;\"\\\n",
    "                    \"supervised_loss;supervised_acc;\"\\\n",
    "                    \"train_loss;test_loss;\"\\\n",
    "                    \"train_mse;test_mse;\"\\\n",
    "                    \"train_auc;test_auc;\"\\\n",
    "                    \"train_f1;test_f1;\"\\\n",
    "                    \"train_acc;test_acc\\n\")\n",
    "    \n",
    "    #for epoch in n_epochs:\n",
    "    #    for batch in range(bat_per_epo):\n",
    "    for step in range(1,n_steps+1):\n",
    "#         t_start = time.time()\n",
    "        # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], n_batch)\n",
    "        c_loss, c_acc, _, _, _ = supervised_model.train_on_batch(Xsup_real, ysup_real)\n",
    "        \n",
    "        # update unsupervised discriminator (d)\n",
    "        [X_real, _], y_real = generate_real_samples(dataset_train, n_batch)\n",
    "        d_loss1, real_acc = unsupervised_model.train_on_batch(X_real, y_real)\n",
    "        \n",
    "        X_fake, y_fake = generate_fake_samples(generator_model, latent_dim, n_batch)\n",
    "        d_loss2, fake_acc = unsupervised_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), np.ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "#         t_total = (time.time() - t_start)\n",
    "        # summarize loss on this batch\n",
    "    \n",
    "        # Train - Test\n",
    "        X_train, y_train = dataset_train\n",
    "        loss_train, acc_train, mse_train, f1_train, auc_train = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "        # evaluate the test classifier model\n",
    "        X_test, y_test = dataset_test\n",
    "        loss_test, acc_test, mse_test, f1_test, auc_test = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        # Log\n",
    "        print('epoch: %d | step: %d | Train: G_Loss: %.3f, ' \\\n",
    "              'D_unsup_loss_real: %.3f, D_unsup_acc_real:  %.2f, ' \\\n",
    "              'D_unsup_loss_fake: %.3f, D_unsup_acc_fake: %.2f, ' \\\n",
    "              'D_sup_loss: %.3f, D_sup_acc: %.2f ' \\\n",
    "              'Train auc: %.3f Test auc: %.3f ' \\\n",
    "              'Train f1: %.3f Test f1: %.3f ' \\\n",
    "              'Train acc: %.3f Test acc: %.3f ' %(int(step/bat_per_epo), step, g_loss,\n",
    "                                                d_loss1, real_acc*100,\n",
    "                                                d_loss2, fake_acc*100,\n",
    "                                                c_loss, c_acc*100,\n",
    "                                                auc_train, auc_test,\n",
    "                                                f1_train, f1_test,\n",
    "                                                acc_train*100, acc_test*100))#, end = '\\r')\n",
    "        \n",
    "        f_history.write(f\"{step};{g_loss};\"\\\n",
    "                        f\"{d_loss1};{real_acc*100};\"\\\n",
    "                        f\"{d_loss2};{fake_acc*100};\"\\\n",
    "                        f\"{c_loss};{c_acc*100};\"\\\n",
    "                        f\"{loss_train};{loss_test};\"\\\n",
    "                        f\"{mse_train};{mse_test};\"\\\n",
    "                        f\"{auc_train};{auc_test};\"\\\n",
    "                        f\"{f1_train};{f1_test};\"\\\n",
    "                        f\"{acc_train*100};{acc_test*100}\\n\")\n",
    "        \n",
    "        if step==1:\n",
    "            # plot real samples\n",
    "            plot_data(unnormalize(X_test).astype(int), 0, \"test\", grid_size = [10, 10], OUT_PATH=LOG_PATH)\n",
    "            \n",
    "            # prepare fake examples\n",
    "            X_generated, _ = generate_fake_samples(generator_model, latent_dim, n_samples=100)\n",
    "            # scale from [-1,1] to [0,1]\n",
    "            plot_data(unnormalize(X_generated).astype(int), step, \"generated\", grid_size = [10, 10], OUT_PATH=LOG_PATH)\n",
    "            \n",
    "            # evaluate train set\n",
    "            X_train, y_train = dataset_train\n",
    "            _, acc, _, f1, auc = supervised_model.evaluate(X_train, y_train, verbose=1)\n",
    "            print('Train Classifier Accuracy: %.3f%%, F1: %.3f%%, AUC: %.3f%% \\n' % (acc * 100, f1, auc))\n",
    "            \n",
    "            # evaluate the test classifier model\n",
    "            X_test, y_test = dataset_test\n",
    "            _, acc, _, f1, auc = supervised_model.evaluate(X_test, y_test, verbose=1)\n",
    "            print('Test Classifier Accuracy: %.3f%%, F1: %.3f%%, AUC: %.3f%% \\n' % (acc * 100, f1, auc))\n",
    "            \n",
    "            # save the generator model\n",
    "            filename2 = f'{LOG_PATH}generator_model_{step}.h5'\n",
    "            generator_model.save(filename2)\n",
    "            # save the classifier model\n",
    "            filename3 = f'{LOG_PATH}supervised_model_{step}.h5'\n",
    "            supervised_model.save(filename3)\n",
    "            \n",
    "            print('>Saving models Generator: %s and Supervised: %s' % (filename2, filename3))\n",
    "        \n",
    "        elif (step) % (100) == 0:\n",
    "            # prepare fake examples\n",
    "            X_generated, _ = generate_fake_samples(generator_model, latent_dim, n_samples=100)\n",
    "            # scale from [-1,1] to [0,1]\n",
    "            plot_data(unnormalize(X_generated).astype(int), step, \"generated\", grid_size = [10, 10], OUT_PATH=LOG_PATH)\n",
    "            \n",
    "        elif (step) % (bat_per_epo) == 0:\n",
    "            # prepare fake examples\n",
    "            X_generated, _ = generate_fake_samples(generator_model, latent_dim, n_samples=100)\n",
    "            # scale from [-1,1] to [0,1]\n",
    "            plot_data(unnormalize(X_generated).astype(int), step, \"generated\", grid_size = [10, 10], OUT_PATH=LOG_PATH)\n",
    "            \n",
    "            # evaluate train set\n",
    "            X_train, y_train = dataset_train\n",
    "            _, acc, _, f1, auc = supervised_model.evaluate(X_train, y_train, verbose=1)\n",
    "            print('Train Classifier Accuracy: %.3f%%, F1: %.3f%%, AUC: %.3f%% \\n' % (acc * 100, f1, auc))\n",
    "            \n",
    "            # evaluate the test classifier model\n",
    "            X_test, y_test = dataset_test\n",
    "            _, acc, _, f1, auc = supervised_model.evaluate(X_test, y_test, verbose=1)\n",
    "            print('Test Classifier Accuracy: %.3f%%, F1: %.3f%%, AUC: %.3f%% \\n' % (acc * 100, f1, auc))\n",
    "            \n",
    "            # save the generator model\n",
    "            filename2 = f'{LOG_PATH}generator_model_{step}.h5'\n",
    "            generator_model.save(filename2)\n",
    "            # save the classifier model\n",
    "            filename3 = f'{LOG_PATH}supervised_model_{step}.h5'\n",
    "            supervised_model.save(filename3)\n",
    "            \n",
    "            print('>Saving models Generator: %s and Supervised: %s' % (filename2, filename3))\n",
    "    \n",
    "    f_history.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44673ab8",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "dataset_train, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d9f44",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 2e-4\n",
    "latent_dim = 100\n",
    "\n",
    "epochs=100\n",
    "batch_size=128\n",
    "\n",
    "labeled_rate = 4/50\n",
    "labeled_samples = int(dataset_train[0].shape[0]*labeled_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e13f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = f\"Logs/SSGAN_CIFAR10/Classifier_{labeled_samples}/\"\n",
    "verifyDir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bb54a",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2af08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import f1_score, auc_pr, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list=[\"accuracy\", f1_score, auc_pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b4edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the discriminator models\n",
    "unsupervised_model, supervised_model = define_discriminator(in_shape=input_shape, \n",
    "                                                            n_classes=num_classes, \n",
    "                                                            learning_rate = learning_rate,\n",
    "                                                            metrics_list=metrics_list)\n",
    "# create the generator\n",
    "generator_model = define_generator(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c16f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a9e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unsupervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c913e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b591f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the gan\n",
    "from keras.optimizers import Adam\n",
    "opt_gan = Adam(lr=learning_rate, beta_1=0.5)\n",
    "\n",
    "gan_model = define_gan(generator_model, unsupervised_model, optimizer_grad = opt_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187649bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680572f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ab1f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gan(generator_model, unsupervised_model, supervised_model, gan_model, \n",
    "      dataset_train, dataset_test, latent_dim=latent_dim, \n",
    "      n_epochs=epochs, n_batch=batch_size, n_classes=num_classes, \n",
    "      # n_samples=labeled_samples)\n",
    "      label_rate=labeled_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff849fc",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85341c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_step = int(dataset_train[0].shape[0]/batch_size)*epochs\n",
    "last_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model = load_model(f'{LOG_PATH}supervised_model_{last_step}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db02aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = dataset_train\n",
    "_, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbae68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = dataset_test\n",
    "_, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af00c9",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = pd.read_csv(f\"{LOG_PATH}SSL_GAN.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9475a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = results_file.iloc[:,1:]\n",
    "log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = log_file[[\"generator_loss\", \"unsupervised_real_loss\", \"unsupervised_fake_loss\", \"supervised_loss\"]].plot(figsize=(16,12)).get_figure()\n",
    "fig.savefig(f'{LOG_PATH}GAN_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = log_file[[\"train_loss\", \"test_loss\"]].plot(figsize=(16,12)).get_figure()\n",
    "fig.savefig(f'{LOG_PATH}train_test_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = log_file[[\"train_acc\", \"test_acc\"]].plot(figsize=(16,12), ylim=(0,100), yticks=range(0,110,10)).get_figure()\n",
    "fig.savefig(f'{LOG_PATH}train_test_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfe4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = log_file[[\"unsupervised_real_acc\", \"unsupervised_fake_acc\"]].plot(figsize=(16,12), ylim=(0,100), yticks=range(0,110,10)).get_figure()\n",
    "fig.savefig(f'{LOG_PATH}unsupervised_real_fake_acc.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
