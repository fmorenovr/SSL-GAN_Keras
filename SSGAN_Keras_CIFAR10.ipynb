{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a207473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac806c7a",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c569491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import verifyDir\n",
    "from utils.networks import normalize, unnormalize, plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3c765",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e460c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CIFAR10 import load_real_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc42eb",
   "metadata": {},
   "source": [
    "### Discriminator & Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da029db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CIFAR10 import define_discriminator\n",
    "from utils.CIFAR10 import define_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417a6ca",
   "metadata": {},
   "source": [
    "### Semi-Supervised GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import define_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea76a5",
   "metadata": {},
   "source": [
    "### Selecting sub-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import select_supervised_samples, generate_real_samples\n",
    "from utils.networks import generate_fake_samples, generate_latent_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9408523",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(generator_model, unsupervised_model, supervised_model, gan_model, dataset_train, dataset_test, \n",
    "          latent_dim=100, n_epochs=20, n_batch=100, n_samples=100, n_classes=10):\n",
    "    \n",
    "    # select supervised dataset_train\n",
    "    X_sup, y_sup = select_supervised_samples(dataset_train, n_samples=n_samples, n_classes=n_classes)\n",
    "    print(\"Sup samples:\", X_sup.shape, y_sup.shape)\n",
    "    \n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset_train[0].shape[0] / n_batch)\n",
    "    \n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    print('n_epochs=%d, n_batch=%d, batch/epoch=%d, steps=%d' % (n_epochs, n_batch, bat_per_epo, n_steps))\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    f_history = open(f\"{LOG_PATH}SSL_GAN.csv\", \"w\")\n",
    "    \n",
    "    f_history.write(\"step,generator_loss,\\\n",
    "                    unsupervised_real_loss,unsupervised_real_acc,\\\n",
    "                    unsupervised_fake_loss,unsupervised_fake_acc,\\\n",
    "                    supervised_loss,supervised_acc,\\\n",
    "                    train_loss,test_loss,\\\n",
    "                    train_acc,test_acc\\n\")\n",
    "    \n",
    "    #for epoch in n_epochs:\n",
    "    #    for batch in range(bat_per_epo):\n",
    "    for step in range(1,n_steps+1):\n",
    "#         t_start = time.time()\n",
    "        # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], n_batch)\n",
    "        c_loss, c_acc = supervised_model.train_on_batch(Xsup_real, ysup_real)\n",
    "        \n",
    "        # update unsupervised discriminator (d)\n",
    "        [X_real, _], y_real = generate_real_samples(dataset_train, n_batch)\n",
    "        d_loss1, real_acc = unsupervised_model.train_on_batch(X_real, y_real)\n",
    "        \n",
    "        X_fake, y_fake = generate_fake_samples(generator_model, latent_dim, n_batch)\n",
    "        d_loss2, fake_acc = unsupervised_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), np.ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "#         t_total = (time.time() - t_start)\n",
    "        # summarize loss on this batch\n",
    "    \n",
    "        # Train - Test\n",
    "        X_train, y_train = dataset_train\n",
    "        loss_train, acc_train = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "        # evaluate the test classifier model\n",
    "        X_test, y_test = dataset_test\n",
    "        loss_test, acc_test = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        # Log\n",
    "        print('epoch: %d | step: %d | Train: G_Loss: %.3f, ' \\\n",
    "              'D_unsup_loss_real: %.3f, D_unsup_acc_real:  %.2f, ' \\\n",
    "              'D_unsup_loss_fake: %.3f, D_unsup_acc_fake: %.2f, ' \\\n",
    "              'D_sup_loss: %.3f, D_sup_acc: %.2f ' \\\n",
    "              'Train acc: %.3f Test acc: %.3f ' %(int(step/bat_per_epo), step, g_loss,\n",
    "                                                d_loss1, real_acc*100,\n",
    "                                                d_loss2, fake_acc*100,\n",
    "                                                c_loss, c_acc*100,\n",
    "                                                acc_train*100, acc_test*100))#, end = '\\r')\n",
    "        \n",
    "        f_history.write(f\"{step},{g_loss},\\\n",
    "                          {d_loss1},{real_acc*100}\\\n",
    "                          {d_loss2},{fake_acc*100}\\\n",
    "                          {c_loss},{c_acc*100},\\\n",
    "                          {loss_train},{loss_test},\\\n",
    "                          {acc_train*100},{acc_test*100}\\n\")\n",
    "        \n",
    "        if step==1:\n",
    "            plot_data(unnormalize(X_test).astype(int), 0, \"test\", grid_size = [10, 10], OUT_PATH=LOG_PATH)\n",
    "        # evaluate the model performance every so often\n",
    "        if (step) % (100) == 0 or step == 1:\n",
    "            #summarize_performance(step, generator_model, supervised_model, latent_dim, dataset, dataset_test)\n",
    "            # prepare fake examples\n",
    "            X_generated, _ = generate_fake_samples(generator_model, latent_dim, n_samples=100)\n",
    "            # scale from [-1,1] to [0,255]\n",
    "            plot_data(unnormalize(X_generated).astype(int), step, \"generated\", grid_size = [10, 10], OUT_PATH=LOG_PATH)\n",
    "            \n",
    "            X_train, y_train = dataset_train\n",
    "            _, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "            print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))\n",
    "            \n",
    "            # evaluate the test classifier model\n",
    "            X_test, y_test = dataset_test\n",
    "            _, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "            print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))\n",
    "            \n",
    "            # save the generator model\n",
    "            filename2 = f'{LOG_PATH}generator_model_{step}.h5'\n",
    "            generator_model.save(filename2)\n",
    "            # save the classifier model\n",
    "            filename3 = f'{LOG_PATH}supervised_model_{step}.h5'\n",
    "            supervised_model.save(filename3)\n",
    "            \n",
    "            print('>Saving models Generator: %s and Supervised: %s' % (filename2, filename3))\n",
    "    \n",
    "    f_history.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44673ab8",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "dataset_train, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d9f44",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 0.0002\n",
    "latent_dim = 100\n",
    "\n",
    "epochs=100\n",
    "batch_size=128\n",
    "\n",
    "labeled_rate = 4/50\n",
    "labeled_samples = int(dataset_train.shape[0]*labeled_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e13f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = f\"Logs/SSGAN_CIFAR10/Classifier_{labeled_samples}/\"\n",
    "verifyDir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bb54a",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b4edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the discriminator models\n",
    "unsupervised_model, supervised_model = define_discriminator(in_shape=input_shape, \n",
    "                                                            n_classes=num_classes, \n",
    "                                                            learning_rate = learning_rate)\n",
    "# create the generator\n",
    "generator_model = define_generator(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c16f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a9e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unsupervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c913e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b591f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the gan\n",
    "from keras.optimizers import Adam\n",
    "opt_gan = Adam(lr=learning_rate, beta_1=0.5)\n",
    "\n",
    "gan_model = define_gan(generator_model, unsupervised_model, optimizer_grad = opt_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187649bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680572f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ab1f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(generator_model, unsupervised_model, supervised_model, gan_model, \n",
    "      dataset_train, dataset_test, latent_dim=latent_dim, \n",
    "      n_epochs=epochs, n_batch=batch_size, n_samples=labeled_samples, \n",
    "      n_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff849fc",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85341c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_step = int(dataset_train.shape[0]/batch_size)*epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_model = load_model(f'{LOG_PATH}supervised_model_{last_step}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db02aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = dataset_train\n",
    "_, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbae68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = dataset_test\n",
    "_, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af00c9",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = pd.read_csv(f\"{LOG_PATH}SSL_GAN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9475a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = results_file.iloc[:,1:]\n",
    "log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.iloc[:, [0,1,2,3]].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb08f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.iloc[:, [5,6]].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.iloc[:, [7,8]].plot(figsize=(12,8), ylim=(0,100), yticks=range(0,110,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
