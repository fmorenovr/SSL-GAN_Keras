{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of semi-supervised gan for mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from numpy.random import randn, randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Dropout, Lambda, Activation\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c569491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import verifyDir\n",
    "from utils.networks import normalize, unnormalize, plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dd749",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_height, x_width = [28, 28]\n",
    "num_channels = 1\n",
    "input_shape = (x_height, x_width, num_channels)\n",
    "num_classes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 2e-5\n",
    "# optimizer\n",
    "optimizer_grad = Adam(lr=learning_rate, beta_1=0.5)\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "\n",
    "epochs=30\n",
    "batch_size=128\n",
    "labeled_rate = 1/600\n",
    "labeled_samples = 60000*labeled_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50879c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = f\"Logs/SSGAN_MNIST/Classifier_{int(labeled_samples)}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "verifyDir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ef1bc",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images MNIST\n",
    "def load_real_samples():\n",
    "    # load dataset\n",
    "    (trainX, trainy), (testX, testy) = load_data()\n",
    "    # expand to 3d, e.g. add channels\n",
    "    X_train = np.expand_dims(trainX, axis=-1)\n",
    "    X_test = np.expand_dims(testX, axis=-1)\n",
    "    X_test = normalize(X_test)\n",
    "    X_train = normalize(X_train)\n",
    "    print(X_train.shape, trainy.shape, X_test.shape, testy.shape)\n",
    "    return [X_train, trainy], [X_test, testy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc42eb",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598097c3",
   "metadata": {},
   "source": [
    "Custom Activation for the Unsupervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom activation function\n",
    "def custom_activation(output):\n",
    "    logexpsum = K.sum(K.exp(output), axis=-1, keepdims=True)\n",
    "    result = logexpsum / (logexpsum + 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732ee23",
   "metadata": {},
   "source": [
    "Defines a unsupersived output and supervised output.  \n",
    "Both shared the same weights until the last Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ad3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone supervised and unsupervised discriminator models\n",
    "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(in_image)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # flatten feature maps\n",
    "    fe = Flatten()(fe)\n",
    "    # dropout\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    # output layer nodes\n",
    "    fe = Dense(n_classes)(fe)\n",
    "    \n",
    "    # supervised output\n",
    "    c_out_layer = Activation('softmax')(fe)\n",
    "    # define and compile supervised discriminator model\n",
    "    supervised_model = Model(in_image, c_out_layer)\n",
    "    supervised_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer_grad, metrics=['accuracy'])\n",
    "    \n",
    "    # unsupervised output\n",
    "    d_out_layer = Lambda(custom_activation)(fe)\n",
    "    # define and compile unsupervised discriminator model\n",
    "    unsupervised_model = Model(in_image, d_out_layer)\n",
    "    unsupervised_model.compile(loss='binary_crossentropy', optimizer=optimizer_grad)\n",
    "    \n",
    "    return unsupervised_model, supervised_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717aa06",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "    # upsample to 14x14\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # upsample to 28x28\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # output\n",
    "    out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
    "    # define model\n",
    "    generator_model = Model(in_lat, out_layer)\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417a6ca",
   "metadata": {},
   "source": [
    "### Semi-Supervised GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19150400",
   "metadata": {},
   "source": [
    "We let the unsupervised model as not trainable, because we gonna trin the weights of the supervised model (which shares weights with the unsupervised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d003e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator_model, unsupervised_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    unsupervised_model.trainable = False\n",
    "    # connect image output from generator as input to discriminator\n",
    "    gan_output = unsupervised_model(generator_model.output)\n",
    "    # define gan model as taking noise and outputting a classification\n",
    "    model = Model(generator_model.input, gan_output)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer_grad)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1de47",
   "metadata": {},
   "source": [
    "### Selecting sub-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b274f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a supervised subset of the dataset, ensures classes are balanced\n",
    "def select_supervised_samples(dataset, percent_samples=1.0, n_classes=10):\n",
    "    X, y = dataset\n",
    "    X_list, y_list = list(), list()\n",
    "    #n_per_class = int(n_samples / n_classes)\n",
    "    for i in range(n_classes):\n",
    "        # get all images for this class\n",
    "        X_with_class = X[y == i]\n",
    "        # choose random instances\n",
    "        ix = randint(0, len(X_with_class), int(len(X_with_class)*percent_samples))\n",
    "        # add to list\n",
    "        [X_list.append(X_with_class[j]) for j in ix]\n",
    "        [y_list.append(i) for j in ix]\n",
    "    return np.asarray(X_list), np.asarray(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db7444",
   "metadata": {},
   "source": [
    "### Getting Real Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples=100):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a62b47",
   "metadata": {},
   "source": [
    "### Getting Fake Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples=100):\n",
    "    # generate points in the latent space\n",
    "    z_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = z_input.reshape(n_samples, latent_dim)\n",
    "    return z_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba86e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples=100):\n",
    "    # generate points in latent space\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict(z_input)\n",
    "    # create class labels\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return images, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069f9b9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(generator_model, unsupervised_model, supervised_model, gan_model, dataset, dataset_test, latent_dim, n_epochs=20, n_batch=100, percent_samples=1.0):\n",
    "    # select supervised dataset\n",
    "    X_sup, y_sup = select_supervised_samples(dataset, percent_samples=percent_samples)\n",
    "    print(X_sup.shape, y_sup.shape)\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    print('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "    # manually enumerate epochs\n",
    "    f_history = open(f\"{LOG_PATH}SSL_GAN.csv\", \"w\")\n",
    "    f_history.write(\"step,generator_loss,unsupervised_real_loss,unsupervised_fake_loss,supervised_loss,supervised_acc,train_loss,test_loss,train_acc,test_acc\\n\")\n",
    "    for step in range(1,n_steps+1):\n",
    "#         t_start = time.time()\n",
    "        # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], half_batch)\n",
    "        c_loss, c_acc = supervised_model.train_on_batch(Xsup_real, ysup_real)\n",
    "        \n",
    "        # update unsupervised discriminator (d)\n",
    "        [X_real, _], y_real = generate_real_samples(dataset, half_batch)\n",
    "        d_loss1 = unsupervised_model.train_on_batch(X_real, y_real)\n",
    "        \n",
    "        X_fake, y_fake = generate_fake_samples(generator_model, latent_dim, half_batch)\n",
    "        d_loss2 = unsupervised_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), np.ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "#         t_total = (time.time() - t_start)\n",
    "        # summarize loss on this batch\n",
    "    \n",
    "        # Train - Test\n",
    "        X_train, y_train = dataset\n",
    "        loss_train, acc_train = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "        # evaluate the test classifier model\n",
    "        X_test, y_test = dataset_test\n",
    "        loss_test, acc_test = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        # Log\n",
    "        print('step: %d | Train: G_Loss: %.3f, ' \\\n",
    "              'D_unsup_loss_real: %.3f, D_unsup_loss_fake: %.3f, ' \\\n",
    "              'D_sup_loss: %.3f, D_sup_acc: %.2f ' \\\n",
    "              'Train acc: %.3f Test acc: %.3f ' %(step, g_loss,\n",
    "                                                d_loss1, d_loss2,\n",
    "                                                c_loss, c_acc*100,\n",
    "                                                 acc_train*100, acc_test*100))#, end = '\\r')\n",
    "        f_history.write(f\"{step},{g_loss},{d_loss1},{d_loss2},{c_loss},{c_acc*100},{loss_train},{loss_test},{acc_train*100},{acc_test*100}\\n\")\n",
    "        \n",
    "        if step==1:\n",
    "            plot_data(X_test, 0, \"test\", grid_size = [10, 10], OUT_PATH=LOG_PATH, gray=True)\n",
    "        # evaluate the model performance every so often\n",
    "        if (step) % (100) == 0 or step == 1:\n",
    "            #summarize_performance(step, generator_model, supervised_model, latent_dim, dataset, dataset_test)\n",
    "            # prepare fake examples\n",
    "            X_generated, _ = generate_fake_samples(generator_model, latent_dim, n_samples=100)\n",
    "            # scale from [-1,1] to [0,1]\n",
    "            plot_data(X_generated, step, \"generated\", grid_size = [10, 10], OUT_PATH=LOG_PATH, gray=True)\n",
    "            \n",
    "            X_train, y_train = dataset\n",
    "            _, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "            print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))\n",
    "            \n",
    "            # evaluate the test classifier model\n",
    "            X_test, y_test = dataset_test\n",
    "            _, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "            print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))\n",
    "            # save the generator model\n",
    "            filename2 = f'{LOG_PATH}generator_model_{step}.h5'\n",
    "            generator_model.save(filename2)\n",
    "            # save the classifier model\n",
    "            filename3 = f'{LOG_PATH}supervised_model_{step}.h5'\n",
    "            supervised_model.save(filename3)\n",
    "            print('>Saving models Generator: %s and Supervised: %s' % (filename2, filename3))\n",
    "    \n",
    "    f_history.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b4edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the discriminator models\n",
    "unsupervised_model, supervised_model = define_discriminator(in_shape=input_shape,n_classes=num_classes)\n",
    "# create the generator\n",
    "generator_model = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator_model, unsupervised_model)\n",
    "# load image data\n",
    "dataset, dataset_test = load_real_samples()\n",
    "# train model\n",
    "train(generator_model, unsupervised_model, supervised_model, gan_model, dataset, dataset_test, latent_dim, n_epochs=epochs, n_batch=batch_size, percent_samples=labeled_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaaf366",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db02aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = dataset\n",
    "_, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbae68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = dataset_test\n",
    "_, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
