{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5077c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85eeb768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e479c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7510f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3ba47",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c569491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import verifyDir\n",
    "from utils.networks import normalize, unnormalize, plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ef1bc",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9127328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.MNIST import load_real_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc42eb",
   "metadata": {},
   "source": [
    "### Discriminator & Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a66d0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.MNIST import define_discriminator\n",
    "from utils.MNIST import define_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417a6ca",
   "metadata": {},
   "source": [
    "### Semi-Supervised GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe016b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import define_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1de47",
   "metadata": {},
   "source": [
    "### Selecting sub-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0232d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.networks import select_supervised_samples, generate_real_samples\n",
    "from utils.networks import generate_fake_samples, generate_latent_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069f9b9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e26395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(generator_model, unsupervised_model, supervised_model, gan_model, dataset, dataset_test, \n",
    "          latent_dim=100, n_epochs=20, n_batch=100, percent_samples=1.0):\n",
    "    \n",
    "    # select supervised dataset\n",
    "    X_sup, y_sup = select_supervised_samples(dataset, percent_samples=percent_samples)\n",
    "    print(\"Sup samples:\", X_sup.shape, y_sup.shape)\n",
    "    \n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    \n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    print('n_epochs=%d, n_batch=%d, batch/epoch=%d, steps=%d' % (n_epochs, n_batch, bat_per_epo, n_steps))\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    f_history = open(f\"{LOG_PATH}SSL_GAN.csv\", \"w\")\n",
    "    f_history.write(\"step,generator_loss,unsupervised_real_loss,unsupervised_fake_loss,supervised_loss,supervised_acc,train_loss,test_loss,train_acc,test_acc\\n\")\n",
    "    for step in range(1,n_steps+1):\n",
    "#         t_start = time.time()\n",
    "        # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], n_batch)\n",
    "        c_loss, c_acc = supervised_model.train_on_batch(Xsup_real, ysup_real)\n",
    "        \n",
    "        # update unsupervised discriminator (d)\n",
    "        [X_real, _], y_real = generate_real_samples(dataset, n_batch)\n",
    "        d_loss1 = unsupervised_model.train_on_batch(X_real, y_real)\n",
    "        \n",
    "        X_fake, y_fake = generate_fake_samples(generator_model, latent_dim, n_batch)\n",
    "        d_loss2 = unsupervised_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), np.ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "#         t_total = (time.time() - t_start)\n",
    "        # summarize loss on this batch\n",
    "    \n",
    "        # Train - Test\n",
    "        X_train, y_train = dataset\n",
    "        loss_train, acc_train = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "        # evaluate the test classifier model\n",
    "        X_test, y_test = dataset_test\n",
    "        loss_test, acc_test = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        # Log\n",
    "        print('step: %d | Train: G_Loss: %.3f, ' \\\n",
    "              'D_unsup_loss_real: %.3f, D_unsup_loss_fake: %.3f, ' \\\n",
    "              'D_sup_loss: %.3f, D_sup_acc: %.2f ' \\\n",
    "              'Train acc: %.3f Test acc: %.3f ' %(step, g_loss,\n",
    "                                                d_loss1, d_loss2,\n",
    "                                                c_loss, c_acc*100,\n",
    "                                                 acc_train*100, acc_test*100))#, end = '\\r')\n",
    "        f_history.write(f\"{step},{g_loss},{d_loss1},{d_loss2},{c_loss},{c_acc*100},{loss_train},{loss_test},{acc_train*100},{acc_test*100}\\n\")\n",
    "        \n",
    "        if step==1:\n",
    "            plot_data(X_test, 0, \"test\", grid_size = [10, 10], OUT_PATH=LOG_PATH, gray=True)\n",
    "        # evaluate the model performance every so often\n",
    "        if (step) % (100) == 0 or step == 1:\n",
    "            #summarize_performance(step, generator_model, supervised_model, latent_dim, dataset, dataset_test)\n",
    "            # prepare fake examples\n",
    "            X_generated, _ = generate_fake_samples(generator_model, latent_dim, n_samples=100)\n",
    "            # scale from [-1,1] to [0,1]\n",
    "            plot_data(X_generated, step, \"generated\", grid_size = [10, 10], OUT_PATH=LOG_PATH, gray=True)\n",
    "            \n",
    "            X_train, y_train = dataset\n",
    "            _, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "            print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))\n",
    "            \n",
    "            # evaluate the test classifier model\n",
    "            X_test, y_test = dataset_test\n",
    "            _, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "            print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))\n",
    "            # save the generator model\n",
    "            filename2 = f'{LOG_PATH}generator_model_{step}.h5'\n",
    "            generator_model.save(filename2)\n",
    "            # save the classifier model\n",
    "            filename3 = f'{LOG_PATH}supervised_model_{step}.h5'\n",
    "            supervised_model.save(filename3)\n",
    "            print('>Saving models Generator: %s and Supervised: %s' % (filename2, filename3))\n",
    "    \n",
    "    f_history.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dd749",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "675d0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 2e-4\n",
    "\n",
    "labeled_rate = 1/600\n",
    "labeled_samples = 60000*labeled_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50879c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = f\"Logs/SSGAN_MNIST/Classifier_{int(labeled_samples)}/\"\n",
    "verifyDir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17ce88",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0b4edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the discriminator models\n",
    "unsupervised_model, supervised_model = define_discriminator(in_shape=input_shape, n_classes=num_classes, learning_rate = learning_rate)\n",
    "# create the generator\n",
    "generator_model = define_generator(latent_dim=100)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator_model, unsupervised_model, learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07563b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 128)       1280      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 316,938\n",
      "Trainable params: 0\n",
      "Non-trainable params: 316,938\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "supervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac35634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 1)         6273      \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 316938    \n",
      "=================================================================\n",
      "Total params: 1,481,227\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 316,938\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b39aa4",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "dataset, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abcddd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822af4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(generator_model, unsupervised_model, supervised_model, gan_model, \n",
    "      dataset, dataset_test, latent_dim=100, \n",
    "      n_epochs=30, n_batch=128, percent_samples=labeled_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaaf366",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_test = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fceaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# supervised_model = load_model(f'{LOG_PATH}supervised_model_14000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db02aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = dataset\n",
    "_, acc = supervised_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbae68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = dataset_test\n",
    "_, acc = supervised_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Classifier Accuracy: %.3f%%\\n' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384510a7",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60143bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c84f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = pd.read_csv(f\"{LOG_PATH}SSL_GAN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc965f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = results_file.iloc[:,1:]\n",
    "log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.iloc[:, [0,1,2,3]].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8116fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.iloc[:, [5,6]].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.iloc[:, [7,8]].plot(figsize=(12,8), ylim=(0,100), yticks=range(0,110,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
